   36  awk -F"\t" '{print $6}' downloaded_tweets_extend_original_nolf2_NOBOT.tsv >> in_reply_to_user_id.txt
   37  ls
   38  head in_reply_to_user_id.txt
   39  cat in_reply_to_user_id.txt
   40  sort in_reply_to_user_id.txt | unique -c } sort -n | tail
   41  sort in_reply_to_user_id.txt | unique -c | sort -n | tail
   42  grep retweeted in_reply_to_user_id.txt
   43  grep retweeted in_reply_to_user_id.txt | head -n 10
   44  cd
   45  pwd
   46  ls
   47  cd A2/
   48  pwd
   49  ls
   50  cut -f 2,6exit
   51  exit
   52  cd A2/
   53  pwd
   54  ls
   55  head -n 5 downloaded_tweets_extend_original_nolf2_NOBOT.tsv
   56  awk -F "\t" '{print$2}' downloaded_tweets_extend_original_nolf2_NOBOT.tsv >> authors.txt
   57  ls
   58  head -n 5 authors.txt
   59  sort authors.txt | unique -c | sort -n | tail -10
   60  sort authors.txt | uniq -c | sort -n | tail -10
   61  awk -F "\t" '{print$2}' downloaded_tweets_extend_original_nolf2_NOBOT.tsv | head -n 1-
   62  awk -F "\t" '{print$2}' downloaded_tweets_extend_original_nolf2_NOBOT.tsv | head -n 10
   63  ls
   64  rm in_reply_to_user_id.txt
   65  ls
   66  awk -F "\t" '{print$6}' downloaded_tweets_extend_original_nolf2_NOBOT.tsv >> reply_user_id.txt
   67  ls
   68  sort reply_user_id.txt | uniq -c | sort -n | tail -10
   69  head -n downloaded_tweets_extend_nolf2_NOBOT.tsv
   70  head -5 downloaded_tweets_extend_nolf2_NOBOT.tsv
   71  ghghjls
   72  ls
   73  awk -F "\t" '{print$6}' downloaded_tweets_extend_nolf2_NOBOT.tsv >> reply.txt
   74  ls
   75  grep "retweeted" reply.txt | sort -n | tail -10
   76  grep "type=retweeted" reply.txt
   77  head reply.txt
   78  rm reply.txt
   79  ls
   80  exit
   81  ls
   82  rm cmds.log
   83  ls
   84  cd A2
   85  pwd
   86  ls
   87  ls -latr
   88  cut -d "\t" -f 2 downloaded_tweets_extend_original_nolf2_NOBOT.tsv > a.txt
   89  cut --help
   90  q
   91  ut -d "\" -f 2 downloaded_tweets_extend_original_nolf2_NOBOT.tsv > a.txt
   92  q
   93  exit
   94  wq
   95  cut -d "\" -f 2 downloaded_tweets_extend_original_nolf2_NOBOT.tsv > a.txt
   96  cut -d "\" -f 2 downloaded_tweets_extend_original_nolf2_NOBOT.tsv >> a.txt
   97  ls
   98  cd A2/
   99  pwd
  100  ls
  101  rm a.txt
  102  rm authors.txt
  103  rm reply_user_id.txt
  104  ls
  105  cut -d "\" -f 2 downloaded_tweets_extend_original_nolf2_NOBOT.tsv >> a.txt
  106  ls
  107  cd
  108  ls
  109   rm README
  110  ls
  111  cd A2
  112  pwd
  113  ls -latr
  114  cut -f 2 -d " " downloaded_tweets_extend_original_nolf2_NOBOT.tsv >> a.txt
  115  ls
  116  sort a.txt |uniq - c| sort -n | tail -10
  117  head -n 5 a.txt
  118  sort -n a.txt | uniq -c | head
  119  head downloaded_tweets_extend_original_nolf2_NOBOT.tsv
  120  cut -f 2 -d "\" downloaded_tweets_extend_original_nolf2_NOBOT.tsv >> b.txt
  121  cut -f 2 -d "/" downloaded_tweets_extend_original_nolf2_NOBOT.tsv >> c.txt
  122  head c.txt
  123  ls
  124  rm c
  125  rm c.txt
  126  rm a.txt
  127  ls
  128  awk -F "\" '{print $2}' downloaded_tweets_extend_original_nolf2_NOBOT.tsv >> a.txt
  129  awk -F "\t" '{print $2}' downloaded_tweets_extend_original_nolf2_NOBOT.tsv >> a.txt
  130  ls
  131  head a.txt
  132  sort a.txt | uniq - c | sort -n | tail -10
  133  sort a.txt | uniq - c | sort -n |
  134  sort -n a.txt |uniq -c
  135  sort -n a.txt |uniq -c |tail -10
  136  sort -n a.txt |uniq -c |tail
  137  sort a.txt |uniq -c |sort -n |tail -n
  138  sort a.txt |uniq -c |sort -n |tail -15
  139  sort a.txt |uniq -c |sort -n |tail -10
  140  ls
  141  awk -F "\t" '{print $6}' downloaded_tweets_extend_original_nolf2_NOBOT.tsv >> u.txt
  142  sort u.txt |uniq -c |sort -n | tail -10
  143  head downloaded_tweets_extend_nolf2_NOBOT.tsv
  144  awk -F "\t" '{print $5}' downloaded_tweets_extend_nolf2_NOBOT.tsv >> b.txt
  145  grep "retweeted" b.txt >> d.txt
  146  sort d.txt | uniq -c | sort -n | tail -10
  147  ls
  148  head downloaded_tweets_extend_nolf2_NOBOT.tsv
  149  awk -F "\t" '{print $4}' downloaded_tweets_extend_nolf2_NOBOT.tsv >> f.txt
  150  sed '/^$/d' f.txt
  151  sort f.txt | uniq -c | sort -n | tail -30
  152  tr '[:upper:]' '[:lower:]' f.txt
  153  ls
  154  head downloaded_tweets_extend_nolf2_NOBOT.tsv
  155  ls
  156  head d.txt
  157  head b.txt
  158  head u.txt
  159  cat u.txt
  160  less
  161  less u.txt
  162  ls
  163  head f.txt
  164  awk -F "\t" '{4,5}' downloaded_tweets_extend_nolf2_NOBOT.tsv >> s.txt
  165  awk -F "\t" '{print $4,5}' downloaded_tweets_extend_nolf2_NOBOT.tsv >> s.txt
  166  head s.txt
  167  sort s.txt |uniq -c |sort -n |tail -30
  168  rm s.txt
  169  ls
  170  awk -F "\t" '{print $4, $5}' downloaded_tweets_extend_nolf2_NOBOT.tsv >> s.txt
  171  ls
  172  sort s.txt |uniq -c |sort -n |tail -30
  173  head f.txt
  174  mv d.txt f.txt
  175  head f.txt
  176  cat f.txt
  177  exit
  178  mkdir a2
  179  cp downloaded_tweets_extend_nolf2.tsv a2
  180  cp downloaded_tweets_extend_original_nolf2.tsv
  181  cp downloaded_tweets_extend_original_nolf2.tsv a2
  182  cd a2/
  183  pwd
  184  ls
  185  awk -F "\t" '{print $2}' downloaded_tweets_extend_original_nolf2.tsv >> authors.txt
  186  sort authors.txt |uniq -c |sort -n | tail -10
  187  awk -F "\t" '{print $6}'  downloaded_tweets_extend_original_nolf2.tsv >> replied.txt
  188  sort replied.txt |uniq -c |sort -n |tail -10
  189  awk -F "\t" '{print $5}' downloaded_tweets_extend_nolf2.tsv >> reference.txt
  190  head -n 5 reference.txt
  191  grep "retweeted" reference.txt >> retweeted.txt
  192  sort retweeted,txt |uniq -c |sort -n |tail -10
  193  head retweeted.txt
  194  sort retweeted.txt |uniq -c |sort -n |tail -10
  195  cut -f 4 downloaded_tweets_extend_nolf2.tsv >> hashtags.txt
  196  sort hashtags.txt |uniq -c |sort -n | tail -30
  197  ls
  198  cut -f 4,5 downloaded_tweets_extend_nolf2.tsv >> r.txt
  199  grep "retweeted" r.txt |uniq -c |sort -n |tail -30
  200  grep "replied to" r.txt |uniq -c |sort -n |tail 30
  201  grep "replied to" r.txt |uniq -c |sort -n |tail -30
  202  grep "replied_to" r.txt |uniq -c |sort -n |tail -30
  203  grep "replied_to" r.txt |uniq -c |sort -n |head -30
  204  sed '/^$/d' hashtags.txt
  205  grep "\"" hashtags.txt |uniq -c |sort -n |tail -30
  206  history
  207  script A2.txt
  208  vi A2.txt
  209  git add A2.txt
  210  git status
  211  git branch -M main
  212  git commit -m "first commit"
  213  git remote add origin https://github.com/shamikamm/A2.git
  214  git remote rm origin
  215  git remote add origin https://github.com/shamikamm/A2.git
  216  git push -u origin main
  217  exit
  218  ls
  219  rm ws4_1.txt
  220  ls
  221  rm ws4.txt
  222  ls
  223  rm ws3.txt
  224  rm a1.txt
  225  ls
  226  exit
  227  which tmux
  228  mkdir ws5
  229  pwd
  230  cd ws5
  231  pwd
  232  ls
  233  cd
  234  ls
  235  cp amazon_reviews_us_Books_v1_02.tsv ws5
  236  cd ws5
  237  ls
  238  pwd
  239  ls
  240  cd ws5/
  241  ls
  242  head amazon_reviews_us_Books_v1_02.tsv
  243  cut -f 2 -d ' ' amazon_reviews_us_Books_v1_02.tsv | sort -n | uniq -c >> customers.txt
  244  ls
  245  head n5 customers.txt
  246  more customers.txt |head
  247  tail -1000 customers.txt >> c.txt
  248  ls
  249  head c.txt
  250  cd
  251  cd ws3
  252  ls
  253  head customers.txt
  254  cd
  255  cd ws5
  256  pwd
  257  ls
  258  rm c.txt
  259  rm customers.txt
  260  ls
  261  awk -F " " '{print $2}' amazon_reviews_us_Books_v1_02.tsv |sort -n |uniq -c >> customers.txt
  262  ls
  263  head customrs.txt
  264  head customers.txt
  265  rm customers.txt
  266  awk -F " " '{print $2}' amazon_reviews_us_Books_v1_02.tsv |sort -n |uniq -c |tail -1000 >>customers.txt
  267  ls
  268  wc -l customers.txt
  269  head customers.txt
  270  for i in customers.txt
  271  awk -F " " '{print $2}' amazon_reviews_us_Books_v1_02.tsv >> c.txt
  272  sort c.txt |sort -n |uniq -c |tail -1000 >> ci.txt
  273  ls
  274  head ci.txt
  275  rm ci.txt
  276  rm c.txt
  277  ls
  278  for i in customers.txt; do 
  279  awk " " '{print $2}' customers.txt |head
  280  cut -f 2 customers.txt |head -10
  281  cut -f 1 customers.tx |head -10
  282  cut -f 1 customers.txt |head -10
  283  cut -f 2 -d " " customers.txt |head
  284  cut -f 3 customers.txt |head
  285  cut -f 3 customers.txt |tail
  286  for i in customers.txt ; do mv $i 
  287  for i in customers.txt; do mv $i $(CUSTOMERS/$i).txt; done
  288  for i in customers.txt; do mv $i $(basename $1 .txt)/($i).txt
  289  for i in customers.txt; do echo $i >> CUSTOMERS/$i .txt; done
  290  for c in customers.txt; do mv $i "${CUSTOMERS/$i/.txt}"; done
  291  pwd
  292  lss
  293  ls
  294  cs ws5/
  295  cd ws5/
  296  pwd
  297  ls
  298  awk -F " " '{print $2}' amazon_reviews_us_Books_v1_02.tsv |sort -n |uniq -c >>customers.txt
  299  ls
  300  tail customers.txt
  301  for c in customers.txt; do NEWNAME="${i/%.CUSTOMERS/.txt}"; mv -- "$i" "$NEWNAME"; done
  302  for c in customers,txt; do mv $c "${CUSTOMERS/$c.txt}"; done
  303  for c in customers.txt; do $c > "CUSTOMERS/$c.txt"; done
  304  for c in customers.txt; do $c > "CUSTOMERS${c}.txt"; done
  305  for c in customers.txt; do echo $c > $c.txt; done
  306  ls
  307  head customers.txt.txt
  308  cat CUSTOMERScustomers.txt.txt
  309  more CUSTOMERScustomers.txt.txt
  310  rm CUSTOMERScustomers.txt.txt
  311  ls
  312  more customers.txt.txt
  313  rm customers.txt.txt
  314  ls
  315  for c in customers.txt; do echo $c >> "c.txt"; done
  316  ls
  317  more c.txt
  318  git init
  319  mkdir ws5
  320  ls
  321  cp amazon_reviews_us_Books_v1_02.tsv ws5
  322  cd ws5/
  323  pwd
  324  ls
  325  head amazon_reviews_us_Books_v1_02.tsv
  326  ls
  327  awk -F " " '{print $2}' amazon_reviews_us_Books_v1_02.tsv |sort -n |uniq -c |tail -1000 >> customers.txt
  328  ls
  329  head customers.txt
  330  for c in customers.txt; do echo $c; done >> $c.txt
  331  script ws5.txt
  332  history
  333  tmux new-session -s homework
  334  ls
  335  rm Ws1
  336  rmdir Ws1
  337  rm -rf Ws1
  338  rm -rf ws_2
  339  ls
  340  rm -rf ws5
  341  rm -rf ws5.txt
  342  mkdir A3
  343  rm -rf cmds.log
  344  ls
  345  cp downloaded_tweets_extend_nolf2.tsv A3
  346  cp downloaded_tweets_extend_original_nolf2.tsv A3
  347  cd A3/
  348  ls
  349  head downloaded_tweets_extend_nolf2.tsv
  350  awk -F "\t" '{print $6}' downloaded_tweets_extend_nolf2.tsv >> in_reply_to_user_id.txt
  351  ls
  352  head in_reply_to_user_id.txt
  353  awk -F "\t" '{print $1}' |uniq -c
  354  awk -F "\t" '{print $1}' |uniq -c >> d.txt
  355  ls
  356  head d.txt
  357  rm d.txt
  358  ls
  359  rm  in_reply_to_user_id.txt
  360  ls
  361  cd A3
  362  ls
  363  awk -F " " '{print $6, $2}' downloaded_tweets_extend_original_nolf2.tsv >> l.txt
  364  ls
  365  head l.txt
  366  head downloaded_tweets_extend_original_nolf2.tsv
  367  ls
  368  awk -F " " '{print $1}' l.txt |sort -k 1n| uniq -c |awk '{if ($1 >+3){print}}'
  369  cd
  370  ls
  371  quit
  372  exit
  373  ls
  374  cd A3
  375  ls
  376  cut -f 6  downloaded_tweets_extend_original_nolf2.tsv > 6.txt
  377  ls
  378  head 6.txt
  379  tail 6.txt
  380  tail  downloaded_tweets_extend_original_nolf2.tsv
  381  head  downloaded_tweets_extend_original_nolf2.tsv
  382  clear
  383  ls
  384  head l.txt
  385  head 
  386  head downloaded_tweets_extend_original_nolf2.tsv
  387  awk '[print $1}' l.txt |uniq -c |wc -c |sort -k 1n |awk '{if($1>+3){print}}'
  388  awk '{print $1}' l.txt |uniq -c |wc -c |sort -k 1n |awk '{if($1>+3){print}}'
  389  awk '{print $1}' l.txt |uniq -c |wc -c |sort -k 1n
  390  head l.txt
  391  awk '{print $1}' l.txt |uniq -c |wc -c |sort -k 1n |awk '{if($1>=3){print}}'
  392  pwd
  393  ls
  394  cd A3/
  395  ls
  396  rm 6.txt
  397  ls
  398  pwd
  399  ls
  400  A3
  401  ls A3
  402  head l.txt
  403  ls -latr
  404  cd A3
  405  pwd
  406  ls
  407  head l.txt
  408  awk '{print $1}' downloaded_tweets_extend_original_nolf2.tsv |sort wc -c |uniq -c > w.txt
  409  awk '{print $1}' downloaded_tweets_extend_original_nolf2.tsv |wc -c |uniq -c > w.txt
  410  ls
  411  head w.txt
  412  cat w.txt
  413  more w.txt
  414  head downloaded_tweets_extend_original_nolf2.tsv
  415  awk '{print $1}' w.txt | uniq -c | sort -k 1n | awk '{ if ($1 >= 3) {print} }'
  416  awk '{print $1}' l.txt | uniq -c | sort -k 1n | awk '{ if ($1 >= 3) {print} }'
  417  ls
  418  pwd
  419  head -5 downloaded_tweets_extend_nolf2.tsv
  420  head -5 downloaded_tweets_extend_original_nolf2.tsv
  421  cut -f 6 -d " " |head
  422  cut -f 6 |head
  423  ls
  424  cd A3
  425  cut -f 6 -d " " downloaded_tweets_extend_original_nolf2.tsV |head
  426  grep "replied_to" downloaded_tweets_extend_original_nolf2.tsv
  427  clear
  428  ls
  429  grep "replied_to" downloaded_tweets_extend_original_nolf2.tsv >> a.txt
  430  ls
  431  rm l.txt
  432  rm w.txt
  433  ls
  434  a.txt |head -5
  435  head a.txt
  436  mv a.txt replied_to.txt
  437  ls
  438  awk -F "\t" '{print $6,$2}' replied_to.txt |sort -n >> directional_graph.txt
  439  ls
  440  head directional_graph.txt
  441  awk -F "\t" '{print $1}' directional_graph.txt |uniq -c |sort k1n |awk'{if($1>3){print}}' >> reply_cluster.txt
  442  awk -F "\t" '{print $1}' directional_graph.txt |uniq -c |sort k1n |awk'{if($1>3){print}}'
  443  awk -F "\t" '{print $1}' directional_graph.txt |uniq -c |sort -k1n |awk'{if($1>3){print}}'
  444  awk -F "\t" '{print $1}' directional_graph.txt |uniq -c |sort -k1n |awk'{if($1>3)}' >> reply_cluster.txt
  445  awk -F "\t" '{print $1}' directional_graph.txt |uniq -c |sort -k1n >>reply_cluster.txt
  446  ls
  447  head reply_cluster.txt
  448  awk '{if($1>3){print}}' reply_cluster.txt
  449  awk '{if($1>3){print}}' reply_cluster.txt > problem_2.txt
  450  ls
  451  head problem_2.txt
  452  rm problem_2.txt
  453  awk '{if($1>=3){print}}' reply_cluster.txt >> P2.txt
  454  ls
  455  head P2.txt
  456  exit
  457  ls
  458  cd A3/
  459  pwd
  460  ls
  461  gnuplot
  462  /etc/gnuplot-5.4.4/src/gnuplot
  463  exit
  464  ls
  465  cd A3/
  466  pwd
  467  ls
  468  wc -l P2.txt
  469  wc -l directional_graph.txt
  470  wc -l reply_cluster.txt
  471  /etc/gnuplot-5.4.4/scr/gnuplot
  472  /etc/gnuplot-5.4.4/src/gnuplot
  473  ls -latr
  474  stfp shamika@172.31.197.164
  475  exit
  476  display A3.svg
  477  display A3.svö
  478  gls
  479  ls
  480  cd A3/
  481  ls
  482  display A3.svg
  483  ls
  484  cd A3/
  485  ls
  486  display A3.svg
  487  ls
  488  display a3.xterm
  489  cd A3/
  490  pwd
  491  ls
  492  cat A3.svg
  493  clear
  494  ls
  495  /etc/gnuplot-5.4.4/src/gnuplot
  496  gnuplot
  497  /etc/gnuplot-5.4.4/src/gnuplot
  498  ls
  499  display a3.xterm
  500  mkdir ws6
  501  ls
  502  cd amazon_reviews_us_Books_v1_02.tsv ws6
  503  cp amazon_reviews_us_Books_v1_02.tsv ws6
  504  cd ws6/
  505  ls
  506  export DATETIME=`date "ws6"`
  507  ls
  508  cd ws6/
  509  ls
  510  echo DATETIME
  511  ECHO $DATETIME
  512  export $DATETIME=`date`
  513  export DATETIME=`date "+%Ym%d_%H%M%S"`
  514  env
  515  echo $DATETIME
  516  pwd
  517  ls
  518  cd A3/
  519  pwd
  520  ;s
  521  ls
  522  head P2.txt
  523  pwd
  524  ls
  525  export A3.svg
  526  ls
  527  cd A3/
  528  pwd
  529  ls
  530  cd ws6/
  531  ls
  532  cd
  533  mkdir -p /home/shamika/PRODUCTS/
  534  awk -F "\t" '{print 42}' amazon_reviews_us_Books_v1_02.tsv |sort |uniq -c|sort -nr |head -5
  535  head amazon_reviews_us_Books_v1_02.tsv
  536  awk -F "\t" '{print $4}' amazon_reviews_us_Books_v1_02.tsv |sort |uniq -c|sort -nr |head -5
  537  fgrep "0439139597" /mnt/scratch/shamika/amazon_reviews_us_Books_v1_02.tsv > /home/shamika/PRODUCTS/ 0439139597.txt
  538  ls
  539  rm -f A2.txt
  540  ls
  541  DATETIME=$(date +%Y%m%d_%H%M%S)
  542  cp /home/shamika/PRODUCTS/0439139597.txt /home/shamika/PRODUCTS/0439139597.$DATETIME.txt
  543   fgrep "0439139597" /mnt/scratch/shamika/amazon_reviews_us_Books_v1_02.tsv > /home/shamika/PRODUCTS/0439139597.txt
  544  cd
  545  ls
  546  rm PRODUCTS
  547  rm -f PRODUCTS
  548  rm -rf PRODUCTS
  549  ls
  550  cd ws6/
  551  ls
  552  mkdir -p PRODUCTS/
  553  fgrep -h "0439139597" amazon_reviews_us_Books_v1_02.tsv >> PRODUCTS/0439139597.txt
  554  ls
  555  DATETIME=$(date +%Y%m%d_%H%M%S)
  556  cp PRODUCTS/0439139597.txt PRODUCTS/0439139597.$DATETIME.txt
  557  ls
  558  cd PRODUCTS
  559  ls
  560  rm -f PRODUCTS/0439139597.LATEST.txt
  561  ln -s /home/shamika/ws6/PRODUCTS/0439139597.$DATETIME.txt /home/shamika/ws6/PRODUCTS/0439139597.LATEST.txt
  562  cat PRODUCTS/0439139597.LATEST.txt
  563  ls
  564  cat  0439139597.LATEST.txt
  565  exit
  566  ls
  567  cd ws6/
  568  cd PRODUCTS/
  569  ls
  570  rm 0439139597.LATEST.txt
  571  ls
  572  head 0439139597.20221019_021514.txt
  573  head amazon_reviews_us_Books_v1_02.tsv
  574  ls
  575  cd ws6/
  576  cd PEODUCTS
  577  cd PRODUCTS/
  578  ls
  579  hsitory -10
  580  history -10
  581  ls 
  582  cd ws6/
  583  ls
  584  head amazon_reviews_us_Books_v1_02.tsv
  585  cd PRODUCTS/
  586  ls
  587  cat new_product_review >> 0439139597.20221019_021514.txt
  588  cat >> 0439139597.20221019_021514.txt
  589  ln -s /home/shamika/ws6/PRODUCTS/0439139597.$DATETIME.txt /home/shamika/ws6/PRODUCTS/0439139597.LATEST.txt
  590  ls
  591  awk -F "\t" '{print $8}' PRODUCTS/0439139597.LATEST.txt | awk '{total+=1,count++} END {print total/count}' >PRODUCTS/0439139597.AVGRATING.txt
  592  awk -F "\t" '{print $8}' PRODUCTS/0439139597.LATEST.txt | awk '{total+=1,count++} END {print total/count}' > 0439139597.AVGRATING.txt
  593   awk -F "\t" '{print $8}' PRODUCTS/0439139597.LATEST.txt | awk '{total+=1;count++} END {print total/count}' > 0439139597.AVGRATING.txt
  594  awk -F "\t" '{print $8} PRODUCTS/0439139597.LATEST.txt > rating.txt
  595  awk -F "\t" '{print $8} PRODUCTS/0439139597.LATEST.txt >> rating.txt
  596  awk -F "\t" '{print $8}' PRODUCTS/0439139597.LATEST.txt >> rating.txt
  597  head 0439139597.LATEST.txt
  598  cat 0439139597.LATEST.txt
  599  ls
  600  head 0439139597.AVGRATING.txt
  601  head 0439139597.20221019_021514.txt
  602  cut -f 8 -d " " 0439139597.20221019_021514.txt > rating.txt
  603  ls
  604  head rating.txt
  605  rm rating.txt
  606  ls
  607  cut -f 9 -d " " 0439139597.20221019_021514.txt > rating.txt
  608  ls
  609  head rating.txt
  610  cut -f 9 -d ' ' 0439139597.20221019_021514.txt >> r.txt
  611  ls
  612  head r.txt
  613  cut -f 8 0439139597.20221019_021514.txt >> r.txt
  614  cut -f 8 0439139597.20221019_021514.txt >> s.txt
  615  ls
  616  rm rating.txt
  617  rm r.txt
  618  head s.txt
  619  cut -f 8 PRODUCTS/0439139597.LATEST.txt |awk '{total += $1; count++} END {print total/count}' >> PRODUCTS/0431.AVGRATIGN.txt
  620  cut -f 8 PRODUCTS/0439139597.LATEST.txt |awk '{total += $1; count++} END {print total/count}'
  621  ut -cat PRODUCTS/0439139597.LATEST.txt
  622  cat PRODUCTS/0439139597.LATEST.txt
  623  cat0439139597.LATEST.txt
  624  cat 0439139597.LATEST.txt
  625  cut -f 8 PRODUCTS/0439139597.20221019_021514.txt |awk '{total += $1; count++} END {print total/count}' >> avg.txt
  626  cut -f 8 PRODUCTS/0439139597.20221019_021514.txt >> a.txt
  627  head s.txt
  628  awk -F "\t" 'BEGIN{sum=0; count=0}{sum=sum+$8; count=count+1}END{print sum/count}' 0439139597.20221019_021514.txt
  629  awk -F "\t" 'BEGIN{sum=0; count=0}{sum=sum+$8; count=count+1}END{print sum/count}' 0439139597.LATEST.txt >> 0439139597.AVGRATING.txt
  630  crontab -e
  631  ls
  632  history
  633  exit
  634  git init
  635  mkdir ws6
  636  cp amazon_reviews_us_Books_v1_02.tsv ws6
  637  cd ws6/
  638  ls
  639  rm -rf cron.log
  640  ls
  641  vi worksheet6.sh
  642  ls
  643  crontab-l
  644  crontab -l
  645  cd PRODUCTS
  646  mkdir PRODUCTS
  647  fgrep "0439139597" amazon_reviews_us_Books_v1_02.tsv > PRODUCTS/0439139597.txt
  648  cd PRODUCTS/
  649  ls
  650  cp /home/shamika/ws6/PRODUCTS/0439139597.txt /home/shamika/ws6/PRODUCTS/0439139597.$DATETIME.TXT
  651  mv /home/shamika/ws6/PRODUCTS/0439139597.$DATETIME.TXT /home/shamika/ws6/PRODUCTS/0439139597.$DATETIME.txt
  652  ls
  653  echo $DATETIME
  654  vi worksheet6.sh
  655  ls
  656  history
  657  exit
  658  mkdir ws6
  659  cp amazon_reviews_us_Books_v1_02.tsv ws6
  660  cd ws6
  661  mkdir PRODUCTS
  662  fgrep "04391139597" amazon_reviews_us_Books_v1_02.tsv > PRODUCTS/04391139597.txt
  663  DATETIME=$(date +%Y%m%d_%H%M%S)
  664  cd PRODUCTS
  665  ls
  666  cp /home/shamika/ws6/PRODUCTS/04391139597.txt /home/shamika/ws6/PRODUCTS/04391139597.$DATETIME.txt
  667  ls
  668  ln -s /home/shamika/ws6/PRODUCTS/04391139597.$DATETIME.txt home/shamika/ws6/PRODUCTS/04391139597.LATEST.txt
  669  cd
  670  cd ws6
  671  ln -s /home/shamika/ws6/PRODUCTS/04391139597.$DATETIME.txt home/shamika/ws6/PRODUCTS/04391139597.LATEST.txt
  672  vi worsksheet6.sh
  673  ls
  674  cat cron.log
  675  crontab -e
  676  history > cmds.log
  677  history
  678  git init
  679  script WS6.txt
  680  git add WS6.txt
  681  ls
  682  cd ws6
  683  ls
  684  cp cmds.log ~
  685  cd
  686  ls
  687  git add cmds.log
  688  git branch -M main
  689  git commit -m "first commit"
  690  git remote add origin https://github.com/shamikamm/ws6.git
  691  git remove remote origin
  692  git rm remote origin
  693  git remote remove origin
  694  git remote add origin https://github.com/shamikamm/ws6.git
  695  git push -u origin main
  696  gti rm --cashed ws4.txt
  697  git rm --cashed ws4.txt
  698  git rm --cached ws4.txt
  699  git commit -m "ws4 removed"
  700  git push origin
  701  git rm --cached ws3.txt
  702  git commit -m "ws3 removed"
  703  git push origin
  704  git rm --cached a1.txt
  705  git commit -m "a1 removed"
  706  git push origin
  707  git rm --cached A2.txt
  708  git commit -m "A2 removed"
  709  git push origin
  710  git rm --cached README
  711  git commit -m "README removed"
  712  git push origin
  713  git rm --cached ws4_1.txt
  714  git commit -m "ws4_1 removed"
  715  git push origin
  716  git rm --cached ws5.txt
  717  git commit -m "ws5 removed"
  718  git push origin
  719  cd
  720  ls
  721  cd A3/
  722  ls
  723  rm A3.svg
  724  ls
  725  head P2,txt
  726  cat P2.txt
  727  cut -f 1 P2.txt
  728  awk -F "\t" '{print $1} P2.txt > p2_1.txt
  729  awk -F "\t" '{print $1}' P2.txt > p2_1.txt
  730  ls
  731  cat p2_1.txt
  732  exit
  733  ls
  734  cd A3/
  735  ls
  736  exit
  737  ls
  738  cd A3/
  739  ls
  740  display histogram.svg
  741  exit
  742  ls
  743  cd A3
  744  ls
  745  head p2_1.txt
  746  /etc/gnuplot-5.4.4/src/gnuplot
  747  ls
  748  awk -F "\t" '{print $1}' P2.txt > c.txt
  749  ls
  750  rm P2_1.txt
  751  rm -f p2_1.txt
  752  ls
  753  head c.txt
  754  rm -f c.txt
  755  ls
  756  cur -f 1 -d ' ' P2.txt > c.txt
  757  ls
  758  head c.txt
  759  head P2.txt
  760  ls
  761  rm c.txt
  762  ls
  763  cut -f 1 -d ' ' P2.txt > d.txt
  764  ls
  765  head d.txt
  766  cut -f 2 -d ' ' P2.txt > e.txt
  767  ls
  768  rm d.txt
  769  ls
  770  head e.txt
  771  cut -f 5 ' ' P2.txt > f.txt
  772  cut -5 5 -d ' ' P2.txt > f.txt
  773  cut -5 -d ' ' P2.txt > f.txt
  774  cut -f 5 -d ' ' P2.txt > f.txt
  775  ls
  776  rm e.txt
  777  ls
  778  head f.txt
  779  cut -f 4 -d ' ' P2.txt > s.txt
  780  rm f.txt
  781  head s.txt
  782  rm s.txt
  783  ls
  784  sed 's/\t/,/g'  P2.txt > P2_1.txt
  785  ls
  786  head P2_1.txt
  787  awk -F "\t" '{print $1}' directional_graph.txt |uniq -c |sort -k1n |awk -F "\t"'{if($1>=3){print}}' >> P2_2.txt
  788   awk -F "\t" '{print $1}' directional_graph.txt > s.txt
  789  sort s.txt |uniq -c |sort -k1n |head
  790  sort s.txt |uniq -c |sort -k1n |awk -F "\t"'{if($1>=3){print}}' |head
  791  sort s.txt |uniq -c |sort -k1n > t.txt
  792  ls
  793  cd a3/
  794  cd A3/
  795  ls
  796  wc -l P2.txt
  797  ls
  798  cd A3/
  799  ls
  800  rm s.txt
  801  rm -f t.txt
  802  rm -f a3.xterm
  803  ls
  804  rm P2_1.txt
  805  rm P2_2.txt
  806  ls
  807  tail P2.txt
  808  tail replied_to.txt
  809  ls
  810  tail directional_graph.txt
  811  wc -c directional_graph.txt |sort -k 1 -n
  812  wc -c P2.txt |sort -k 1 -n
  813  sort directional_graph.txt |sort -k -n
  814  sort directional_graph.txt |sort -k 1 -n
  815  clear
  816  ls
  817  head directional_graph.txt
  818  cut -f 1 directional_graph.txt |head
  819  awk -F "\t" '{print $6}' replited_to.txt > m.txt
  820  awk -F "\t" '{print $6}' replied_to.txt > m.txt
  821  ls
  822  wc -c m.txt
  823  cd A3/
  824  ls
  825  /etc/gnuplot-5.4.4/src/gnuplot
  826  ls
  827  cd A3/
  828  display file.svg
  829  cd A3/
  830  ls
  831  display file.svg
  832  display histogram.svg
  833  ls
  834  cd A3/
  835  ls
  836  /etc/gnuplot-5.4.4/src/gnuplot
  837  tail P2.txt
  838  /etc/gnuplot-5.4.4/src/gnuplot
  839  wc -l P2.txt
  840  /etc/gnuplot-5.4.4/src/gnuplot
  841  ls -latr
  842  rm histogram.svg
  843  rm file.svg
  844  ls
  845  wc -l m.txt
  846  wc -l P2.txt
  847  /etc/gnuplot-5.4.4/src/gnuplot
  848  cat P2.txt
  849  /etc/gnuplot-5.4.4/src/gnuplot
  850  sort P2.txt |uniq -c|sort -n > P2_1.txt
  851  ls
  852  cat P2_1.txt
  853  /etc/gnuplot-5.4.4/src/gnuplot
  854  ls
  855  rm file.svg
  856  ls
  857  rm m.txt
  858  ls
  859  tail reply_cluster.txt
  860  awk '{if($1!=$2){print}}' reply_cluster.txt > no_bot.txt
  861  ls
  862  tail no_bot.txt
  863  head replied_to.txt
  864  awk '{if($6!=$2){print}}' replied_to.txt >> p.txt
  865  ls
  866  head p.txt
  867  awk -F "\t" '{print $6, $2}' p.txt > q.txt
  868  head q.txt
  869  cat q.txt
  870  rm p.txt
  871  rm q.txt
  872  ls
  873  rm no_bot.txt
  874  ;s
  875  ls
  876  rm p2_1.txt
  877  exit
  878  ls
  879  cd A3/
  880  ls
  881  display histogram.svg
  882  rm histogram.svg
  883  ls
  884  cd A3/
  885  ls
  886  cat P2_1.txt
  887  awk -F "\t" '{if($6!=$2){print}}' replied_to.txt > s.txt
  888  head s.txt
  889  awk -F "\t" '{print $6,$2}' s.txt > z.txt
  890  sort -k 1 -n z.txt > y.txt
  891  cat y.txt
  892  awk "\t"'{if($1>=3){print}}' y.txt > P2_2.txt
  893  awk -F "\t" '{if($1>=3){print}}' y.txt > P2_2.txt
  894  cat P2_2.txt
  895  awk '{if($1>=3){print}}' y.txt > P2_3.txt
  896  head p2_3.txt
  897  head P2_3.txt
  898  tail P2_3.txt
  899  wc -l P2_3.txt
  900  cut -f 1 P2_3.txt |head
  901  cut -f 1 -d ' ' P2_3.txt |tail
  902  sort P2_3.txt |sort -k 1 -n > l.txt
  903  cat l.txt
  904  rm l.txt
  905  sort P2_3.txt |sort -k 1 -n |uniq -c
  906  cut -f 1 -d ' ' P2_3.txt > p.txt
  907  head p.txt
  908  tail p.txt
  909  awk '{if($1>=3){print}}' p.txt > q.txt
  910  cat q.txt
  911  wc -l q.txt
  912  ls
  913  rm z.txt
  914  rm y.txt
  915  rm p.txt
  916  rm q.txt
  917  ls
  918  rm s.txt
  919  rm P2_2.txt
  920  ls
  921  rm P2_1.txt
  922  ls
  923  head directional_graph.txt
  924  cut -f 1 -d ' ' directional_graph.txt |tail
  925  cut -f 1 -d ' ' directional_graph.txt |uniq -c |sort -k 1 -n |awk 'if($1>=3){print}}' > z.txt
  926  cut -f 1 -d ' ' directional_graph.txt |uniq -c |sort -k 1 -n > z.txt
  927  cat z.txt
  928  awk 'if($1>=3){print}}' q.txt > r.txt
  929   awk '{if($1>=3){print}}' q.txt > r.txt
  930  awk '{if($1>=3){print}}' z.txt > r.txt
  931  cat r.txt
  932  /etc/gnuplot-5.4.4/src/gnuplot
  933  ls
  934  history
  935  git init
  936  scruot A3.txt
  937  mkdir A3
  938  ls
  939  cp downloaded_tweets_extend_original_nolf2.tsv A3
  940  cp downloaded_tweets_extend_nolf2.tsv A3
  941  cd A3/
  942  ls
  943  head downloaded_tweets_extend_original_nolf2.tsv
  944  grep "replied_to" downloaded_tweets_extend_original_nolf2.tsv > replied_to.txt
  945  awk -F "\t" '{print $6, $2}' replied_to.txt |sort -n > directional_graph.txt
  946  ls
  947  head directional_graph.txt
  948  awk -F "\t" '{print $1}' directional_graph.txt |uniq -c |sort -k 1 -n > reply_cluster.txt
  949  ls
  950  awk '{if($1>=3){print}}' reply_cluster.txt > problem_2.txt
  951  ls
  952  head problem_2.txt
  953  tail problem_2.txt
  954  /etc/gnuplot-5.4.4/src/gnuplot
  955  cd A3/
  956  ls
  957  cd
  958  ls
  959  exit
  960  ls
  961  rm -rf A3/
  962  ls
  963  /mnt/scratch/shamika
  964  ls
  965  cd /mny/scratch/shamika
  966  cd /mnt/scratch/shamika
  967  ls
  968  mkdir ws7
  969  ls
  970  cp amazon_reviews_us_Books_v1_02.tsv ws7
  971  cd
  972  mkdir ws7
  973  cp amazon_reviews_us_Books_v1_02.tsv ws7
  974  cd ws7/
  975  ls
  976  head amazon_reviews_us_Books_v1_02.tsv
  977  grep "0373836635" amazon_reviews_us_Books_v1_02.tsv > file.txt
  978  ls
  979  cat file.txt
  980  awk -F "\t" '{print $14}' > 0373836635.txt
  981  cut -f 14 -d ' ' file.txt > 0373836635.txt
  982  ls
  983  0373836635.txt
  984  cat 0373836635.txt
  985  rm 0373836635.txt
  986  awk -F "\t" '{print $14}' file.txt > 0373836635.txt
  987  ls
  988  cat 0373836635.txt
  989  sed -e 's/,/\t/' 0373836635.txt -e 's/;/\t/' 0373836635.txt -e 's/and/\t/' 0373836635.txt -e 's/or\t/' 0373836635.txt -e 's/if\t/' 0373836635.txt -e 's/if\t/' 0373836635.txt -e 's/in\t/' 0373836635.txt -e 's/it\t/' 0373836635.txt -e 0373836635.txt > new_0373836635.txt
  990  sed -e 's/,/\t/' 0373836635.txt -e 's/;/\t/' 0373836635.txt -e 's/and/\t/' 0373836635.txt -e 's/or/\t/' 0373836635.txt -e 's/if/\t/' 0373836635.txt -e 's/in/\t/' 0373836635.txt -e 's/it/\t/' 0373836635.txt > new_0373836635.txt
  991  cat new_0373836635.txt
  992  sed -e 's/<[br]>/\t/' new_0373836635.txt > output.txt
  993  ls
  994  cat output.txt
  995  sed 's/<[br /]+>//g ; /^$/d' output.txt
  996  sed 's/<[^>]*>//g ; /^$/d'
  997  sed 's/<[^>]*>//g ; /^$/d' output.txt
  998  history
  999  exit
 1000  mkdir ws7
 1001  git init
 1002  cp amazon_reviews_us_Books_v1_02.tsv ws7
 1003  cd ws7/
 1004  ls
 1005  pwd
 1006  head amazon_reviews_us_Books_v1_02.tsv
 1007  grep "0373836635" amazon_reviews_us_Books_v1_02.tsv > product.txt
 1008  ls
 1009  cat products.txt
 1010  cat product.txt
 1011  awk -F "\t" '{print $14}' product.txt > 0373836635.txt
 1012  ls
 1013  cat 0373836635.txt
 1014  vi commands.txt
 1015  ls
 1016  sed -f commands.txt 0373836635.txt > output.txt
 1017  vi commands.txt
 1018  sed -f commands.txt 0373836635.txt > output.txt
 1019  cat commands.txt
 1020  vi commands.txt
 1021  sed -f commands.txt 0373836635.txt > output.txt
 1022  ls
 1023  rm -rf commands.txt
 1024  ls
 1025  sed 's/,/\t/' 0373836635.txt > no_commas.txt
 1026  sed 's/;/\t/' no_commas.txt > no_semicolon.txt
 1027  sed 's/and//g' no_semicolon.txt > no_and.txt
 1028  sed 's/if//g' no_and.txt > no_in.txt
 1029  sed 's/or//g' no_in.txt > no_or.txt
 1030  sed 's/in//g' no_or.txt > no_if.txt
 1031  sed 's/it//g' no_if.txt > no_it.txt
 1032  sed 's/<[^>]*>//g ; /^$/d' no_it.txt > final_output.txt
 1033  ls
 1034  cat final_output.txt
 1035  history>cmds.log
